\section{The \((a,b,0)\) and \((a,b,1)\) Classes}
\label{sect:ab0-ab1-classes}
\begin{enumerate}
\item In this section, we discuss two \emph{classes} of probability
distributions: \((a,b,0)\) and \((a,b,1)\) classes, which contain many useful
distributions for modelling claim frequency \(N\).
\end{enumerate}
\subsection{The \((a,b,0)\) Class}
\begin{enumerate}
\item Let \(N\) be a nonnegative discrete random variable, and let
\(p_k=\prob{N=k}\) for any \(k\in\N_0\). Then, (the distribution of) \(N\) is
in the \defn{\((a,b,0)\) class} if there exist constants \(a\) and \(b\) such
that
\[
\frac{p_k}{p_{k-1}}=a+\frac{b}{k},\quad\text{for any \(k\ge 1\) (in the support of \(N\))}.
\]
\begin{note}
The relationship above starts with the pair \(p_{\color{violet} 0}\) and
\(p_1\), so the class is called \((a,b,{\color{violet}0})\).
\end{note}
\item For a random variable \(N\) in the \((a,b,0)\) class, once \(a\) and
\(b\) are fixed, the probabilities \(p_1,p_2,\dotsc\) can all be deduced from
\(p_0\). Furthermore, we can deduce the value of \(p_0\) by the fact that
\(p_0+p_1+\dotsb=1\). Thus, all the probabilities \(p_0,p_1,\dotsc\) are fixed
after \(a\) and \(b\) are fixed.

Hence, the values of \(a\) and \(b\) can be used to uniquely characterize a
distribution (provided that it is in the \((a,b,0)\) class).

\item An important result regarding the \((a,b,0)\) class is as follows.
\begin{theorem}
\label{thm:ab0-dist}
Poisson, negative binomial, and binomial distributions are the \emph{only}
(non-degenerate\footnote{This means that a random variable following the
distribution is not non-random.}) distributions in the \((a,b,0)\) class.
\end{theorem}
\begin{pf}
Omitted. (See, e.g., \textcite{sundt1981further}.)
\end{pf}
\item Although here we do not show Poisson, negative binomial, and binomial
distributions are the \emph{only} distributions in the \((a,b,0)\) class, we
will show that they \emph{are} (without the ``only'' part) distributions in the
\((a,b,0)\) class in the following.

\item \label{it:pois-ab0}
For \(N\sim\pois{\lambda}\), for any \(k\in\N\),
\[
\frac{p_k}{p_{k-1}}=\frac{e^{-\lambda}\lambda^k/k!}{e^{-\lambda}\lambda^{k-1}/(k-1)!}
={\color{violet}0}+\frac{\color{orange}\lambda}{k}.
\]
Hence, \(N\sim\pois{\lambda}\) is in the \((a,b,0)\) class with \(\color{violet}a=0\) and
\(\color{orange}b=\lambda\).

\item \label{it:nb-ab0}
For \(N\sim\nb{r,\beta}\), for any \(k\in\N\),
\begin{align*}
\frac{p_k}{p_{k-1}}
&=\frac{\displaystyle \binom{r+k-1}{k}\qty(\frac{1}{1+\beta})\qty(\frac{\beta}{1+\beta})^{k}}
{\displaystyle \binom{r+k-1-1}{k-1}\qty(\frac{1}{1+\beta})\qty(\frac{\beta}{1+\beta})^{k-1}}\\
&=\frac{\beta}{1+\beta}\frac{(r+k-1)(r+k-2)(r+k-3)\dotsb r/k!}{(r+k-2)(r+k-3)\dotsb r/(k-1)!}\\
&=\frac{\beta}{1+\beta}\cdot\underbrace{\frac{r+k-1}{k}}_{1+\frac{r-1}{k}}\\
&={\color{violet}\frac{\beta}{1+\beta}}+\frac{\displaystyle {\color{orange}(r-1)\frac{\beta}{1+\beta}}}{k}.
\end{align*}
Hence, \(N\sim\nb{r,\beta}\) is in the \((a,b,0)\) class with
\(\displaystyle \color{violet}a=\frac{\beta}{1+\beta}>0\) and
\(\displaystyle \color{orange}b=(r-1)\frac{\beta}{1+\beta}\).

\item \label{it:bin-ab0}
For \(N\sim\bin{m,q}\), for any \(k=1,2,\dotsc,n\),
\begin{align*}
\frac{p_k}{p_{k-1}}&=\frac{\displaystyle \binom{m}{k}q^k(1-q)^{n-k}}{\displaystyle \binom{m}{k-1}q^{k-1}(1-q)^{n-k+1}}\\
&=\frac{q}{1-q}\cdot\frac{m(m-1)\dotsb(m-k+2)(m-k+1)/k!}{m(m-1)\dotsb(m-k+2)/(k-1)!}\\
&=\frac{q}{1-q}\cdot\frac{m-k+1}{k}\\
&={\color{violet}-\frac{q}{1-q}}+\frac{\displaystyle \color{orange}(m+1)\frac{q}{1-q}}{k}.
\end{align*}
Hence, \(N\sim\bin{m,q}\) is in the \((a,b,0)\) class with
\(\displaystyle \color{violet}a=-\frac{q}{1-q}<0\) and
\(\displaystyle \color{orange}b=(m+1)\frac{q}{1-q}\).
\item By \cref{thm:ab0-dist}, \labelcref{it:pois-ab0,it:nb-ab0,it:bin-ab0}
include all possibilities for distributions in the \((a,b,0)\) class. Notably,
if a distribution in the \((a,b,0)\) class has a \emph{positive}
(\emph{negative}) \(a\), it must be \emph{negative binomial} (\emph{binomial})
distributed. (Of course, if \(a=0\), it must be Poisson distributed.)
\begin{warning}
We do \underline{not} have \(a<0\implies\text{negative binomial distributed}\)!
\end{warning}

\item We can rewrite the equation in the definition of \((a,b,0)\) class to
\[
k\cdot\frac{p_k}{p_{k-1}}=ka+b\quad\text{for any \(k\ge 1\)},
\]
so \(\displaystyle k\cdot \frac{p_k}{p_{k-1}}\) is linearly related to \(k\).

\begin{note}
Practically, this is helpful for having a quick check on whether the actual
claim frequency in practice is in the \((a,b,0)\) class as follows.
First note the following approximated relationship:
\[
k\cdot \frac{\widehat{p}_k}{\widehat{p}_{k-1}}\approx ka+b
\]
where \(\displaystyle \widehat{p}_k=\frac{\text{no.\ of policies with \(k\)
claims}}{\text{total no.\ of policies considered}}\) for any \(k\in\N_0\).

Then, by plotting \(\displaystyle k\cdot
\frac{\widehat{p}_k}{\widehat{p}_{k-1}}\) against \(k\) (or other means), we
can examine whether a linear relationship is plausible. If such linear
relationship is deemed plausible, we can then use some line fitting technique
to obtain estimated value of \(a\) and \(b\).
\end{note}
\end{enumerate}
\subsection{The \((a,b,1)\) Class}
\begin{enumerate}
\item One main issue of using distribution in the \((a,b,0)\) class
(Poisson/negative binomial/binomial) to model the number of claims \(N\) is
that the probability \(p_0=\prob{N=0}\) is usually unreasonably low. In practice,
especially when the insurance covers some ``rare'' loss, the probability
\(p_0\) is often quite large.

\item To deal with this issue, a simple way is to add a flexibility on the
choice of \(p_0\) on distribution in the \((a,b,0)\) class \faIcon{arrow-right}
resulting in the \emph{\((a,b,1)\) class}.

\item Let \(N\) be a nonnegative discrete random variable with pmf
\(p_k=\prob{N=k}\). Then, (the distribution of) \(N\) is in the \((a,b,1)\)
class if there exist constants \(a\) and \(b\) such that
\[
\frac{p_k}{p_{k-1}}=a+\frac{b}{k}\quad\text{for any \(k\ge {\color{magenta}2}\)},
\]
while \(p_0\) can take any value (as long as none of the probability axioms is
violated).

\begin{note}
The relationship above starts with the pair \(p_{\color{violet} 1}\) and
\(p_2\), so the class is called \((a,b,{\color{violet}1})\).
\end{note}

\item Like the \((a,b,0)\) class, all the probabilities \(p_0,p_1,\dotsc\) are
fixed after \(a\), \(b\), and \(p_0\) are fixed.

Hence, the values of \(a\), \(b\), and \(p_0\) can be used to uniquely
characterize a distribution (provided that it is in the \((a,b,1)\) class).
\end{enumerate}
\subsection{The Zero-Modified \((a,b,1)\) Class}
\begin{enumerate}
\item Another way to make distribution in the \((a,b,0)\) class better model
the number of claims \(N\) is to apply \emph{zero-modification} to the
distribution, which yields a distribution in the \emph{zero-modified
\((a,b,1)\) class}.
\item \label{it:zero-modify-process}
More specifically, the \defn{zero-modification} process is as follows.
\begin{enumerate}
\item Pick any distribution in the \((a,b,0)\) class. Then, we know
\[
\frac{p_k}{p_{k-1}}=a+\frac{b}{k}\quad\text{for any \(k\ge 1\)}.
\]
\item Modify \(p_0\) to an arbitrary number \(p_0^{M}\in(0,1)\) (we exclude 0
and 1 to avoid making the distribution degenerate).
\item Modify the probabilities (in the support) \(p_1\), \(p_2\), \(\dotsc\) to
\(p_1^M=cp_1\), \(p_2^M=cp_2\),\(\dotsc\) respectively, for some constant
\(c\).
\end{enumerate}
Then, \(p_0^M,p_1^M,\dotsc\) form a distribution in the \defn{zero-modified
\((a,b,1)\) class}.

\begin{note}
For any \(k\ge 2\), we have
\[
\frac{p_k^M}{p_{k-1}^M}=\frac{cp_k}{cp_{k-1}}=\frac{p_k}{p_{k-1}}=a+\frac{b}{k}.
\]
Hence, a distribution in the zero-modified \((a,b,1)\) class is also in the
\((a,b,1)\) class.
\end{note}
\item \label{it:zm-const-c-fmla}
The constant \(c\) in \labelcref{it:zero-modify-process} is indeed
uniquely determined, due to the constraint that \(p_0^M+p_1^M+\dotsb=1\):
\[
p_0^M+p_1^M+p_2^M+\dotsb=1
\implies
p_0^M+c(p_1+p_2+\dotsb)=1
\implies
p_0^M+c(1-p_0)=1
\implies
c=\boxed{\frac{1-p_0^M}{1-p_0}}.
\]
\item \label{it:zm-kth-moment}
Let \(N\) be a random variable in the \((a,b,1)\) class, and let \(M\) be
the random variable in the zero-modified \((a,b,1)\) class obtained by applying
zero-modification on the distribution of \(N\). Then, for any \(k\ge 1\), the
\(k\)th moment of \(M\) is
\[
\expv{M^k}=\sum_{j=1}^{\infty}j^kp_j^M 
=\sum_{j=1}^{\infty}j^k {\color{violet}c}p_j
={\color{violet}c}\sum_{j=1}^{\infty}j^k p_j
=\boxed{c\expv{N^k}}
\]
where \(\displaystyle c=\frac{1-p_0^M}{1-p_0}=\frac{1-\prob{M=0}}{1-\prob{N=0}}\).

\item \label{it:zm-pgf-fmlas}
Consider the same setting as \labelcref{it:zm-kth-moment}. Then, the pgf
of \(M\) is
 \[
P_M(t)=p_0^M+tp_1^M+t^2p_2^M
=p_0^M+c(tp_1+t^2p_2+\dotsb)
=\boxed{p_0^M+c(P_N(t)-p_0)}
\]
where \(P_N(t)\) is the pgf of \(N\).

We can further write
\[
p_0^M+c(P_N(t)-p_0)
=\underbrace{p_0^M-cp_0}_{1-c}+cP_N(t)
=\boxed{1-c+cP_N(t)}
\]
which only involves \(c\) and \(P_N(t)\).

\item If we modify \(p_0\) to \(p_0^M=0\) in the zero modification process, we
call the process as \defn{zero-truncation}, and the resulting distribution is
in the \defn{zero-truncated \((a,b,1)\) class}. Furthermore, we usually denote
\(p_k^M\) by \(p_k^T\) instead for any \(k\ge 0\).

\item \label{it:zt-fmlas}
Since zero-truncated \((a,b,1)\) class is essentially a special case of
zero-modified \((a,b,1)\) class, previous formulas in
\labelcref{it:zm-const-c-fmla,it:zm-kth-moment,it:zm-pgf-fmlas} also apply, by
setting \(p_0^M=0\). Particularly:
\begin{itemize}
\item \(\displaystyle c=\frac{1}{1-p_0}\) (where \(p_k^T=cp_k\) for any \(k\ge 1\)).
\item The pgf of \(M\) (obtained by zero-truncating \(N\)) is
\[
P_M(t)=(1-c)+cP_N(t)=\qty(1-\frac{1}{1-p_0})+\frac{1}{1-p_0}P_N(t),
\]
which only involves \(p_0\) and \(P_N(t)\).
\end{itemize}
\end{enumerate}
\subsection{Extended-Truncated Negative Binomial Distribution}
\begin{enumerate}
\item In this section we consider a special way to modify a \emph{negative
binomial distribution} which involves \emph{extension} and \emph{truncation}.

\item To motivate this way of modification, consider a random variable
\(N\sim\nb{r,\beta}\). Its pmf is given by
\[
p_k=\prob{N=k}=\binom{k+r-1}{k}\qty(\frac{1}{1+\beta})^{r}\qty(\frac{\beta}{1+\beta})^{k}
\]
for any \(k\in\N_0\). Recall that the constraints on the parameters are \(r>0\)
and \(\beta>0\).

Now, suppose we (improperly) set \(r\in(-1,0)\) (while \(\beta>0\) still). A
consequence is that
\[
p_0=(1+\beta)^{-r}>1\qqtext{and}p_k<0\text{ for any \(k\in\N\)},
\]
violating the probability axioms.

\item Nevertheless, in this case, we can observe that \(p_0+p_1+\dotsb=1\)
still holds, and the recursive relation for the \((a,b,0)\) class is still
satisfied:
\[
p_k=\qty(a+\frac{b}{k})p_{k-1}\quad\text{for any \(k\in\N\)},
\]
where \(\displaystyle a=\frac{\beta}{1+\beta}\) and \(\displaystyle
b=(r-1)\frac{\beta}{1+\beta}\) (same as \labelcref{it:nb-ab0}). 

So, allowing \(r\in(-1,0)\) is indeed ``mostly'' appropriate with just
``minor'' issues. Hence, we are interested in finding a modification on the
\(\nb{r,\beta}\) distribution to permit \(r\in(-1,0)\) without violating the
probability axioms.

\item This modification contains two elements: \emph{zero-truncation}
(``\emph{truncated}'') and \emph{extending} the possible range of \(r\)
(``\emph{extended}''). We perform zero-truncation on \(N\sim\nb{r,\beta}\)
(where \(r\in(-1,0)\) and \(\beta>0\)), which gives
\[
p_0^T=0\qqtext{and}p_k^T=cp_k\quad\text{for any \(k\in\N\)}
\]
where \(\displaystyle c=\frac{1}{1-p_0}<0\) (as \(p_0>1\)).

\begin{note}
By construction of zero-truncation, we always have
\(p_0^T+p_1^T+p_2^T+\dots+=1\). Furthermore, \(p_k^T\) is nonnegative for any
\(k\in\N_0\) (since \(p_k<0\) for any \(k\in\N\) and \(c<0\)). Thus, the
probability axioms are not violated.
\end{note}

Then, the probabilities \(p_0^T,p_1^T,\dotsc\) form the
\defn{extended-truncated negative binomial distribution} with parameters
\(r\in(-1,0)\) and \(\beta>0\) (denoted by \(\etnb{r,\beta}\)).

\item Since \(\etnb{r,\beta}\) is in the zero-truncated \((a,b,1)\) class,
previous results for this class apply. Particularly, we have the following
recursive formula for the \((a,b,1)\) class:
\[
p_k^T=\qty(a+\frac{b}{k})p_{k-1}^{T}\quad\text{for any \(k\ge 2\)}
\]
where \(\displaystyle a=\frac{\beta}{1+\beta}\) and \(\displaystyle
b=(r-1)\frac{\beta}{1+\beta}\) (same as \labelcref{it:nb-ab0}). 

\item \label{it:steps-compute-etnb-prob}
As a practical note, to compute probabilities for \(\etnb{r,\beta}\)
where \(r\in(-1,0)\) and \(\beta>0\), we carry out the following steps:
\begin{enumerate}
\item Treat it as if it were an ordinary \(\nb{r,\beta}\) distribution and use
the pmf formula to compute
\[
p_k=\binom{k+r-1}{k}\qty(\frac{\beta}{1+\beta})^{k}\qty(\frac{1}{1+\beta})^{r}
\]
for all \(k\) needed (possibly depending on the method chosen in the second
step below).  Particularly:
\begin{itemize}
\item \(\displaystyle p_0=\qty(\frac{1}{1+\beta})^{r}>1\).
\item \(\displaystyle p_1=r\qty(\frac{1}{1+\beta})^{r}\qty(\frac{\beta}{1+\beta})<0\).
\end{itemize}
\item The desired \(\etnb{r,\beta}\) probabilities can then be obtained by one
of the following methods.
\begin{enumerate}
\item Directly use the following:
\[
p_0^T=0\qqtext{and}p_k^T=cp_k\quad\text{for any \(k\in\N\)}
\]
where \(\displaystyle c=\frac{1}{1-p_0}\).
\item First compute \(p_1^T=cp_1\), and then use the following recursive
formula:
\[
p_k^T=\qty(a+\frac{b}{k})p_{k-1}^{T}\quad\text{for any \(k=2,3,\dotsc\)}
\]
where \(\displaystyle a=\frac{\beta}{1+\beta}\) and \(\displaystyle
b=(r-1)\frac{\beta}{1+\beta}\) (same as \labelcref{it:nb-ab0}).
\end{enumerate}
\end{enumerate}
\end{enumerate}
